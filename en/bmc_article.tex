%% BioMed_Central_Tex_Template_v1.06
%%                                      %
%  bmc_article.tex            ver: 1.06 %
%                                       %

%%IMPORTANT: do not delete the first line of this template
%%It must be present to enable the BMC Submission system to
%%recognise this template!!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%          <8 June 2012>              %%
%%                                     %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.html and the instructions for   %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% additional documentclass options:
%  [doublespacing]
%  [linenumbers]   - put the line numbers on margins

%%% loading packages, author definitions

%\documentclass[twocolumn]{bmcart}% uncomment this for twocolumn layout and comment line below
%\documentclass{bmcart}
\documentclass[doublespacing]{bmcart}

%%% Load packages
%\usepackage{amsthm,amsmath}
%\RequirePackage{natbib}
%\RequirePackage[authoryear]{natbib}% uncomment this for author-year bibliography
%\RequirePackage{hyperref}
\usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails
%\usepackage[latin1]{inputenc} %UNIX support if unicode package fails

\usepackage{url}

\usepackage{graphicx}
\graphicspath{{./figuras/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %%
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %%
%%  submitted article.                         %%
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\def\includegraphic{}
%\def\includegraphics{}



%%% Put your definitions there:
\startlocaldefs
\endlocaldefs


%%% Begin ...
\begin{document}

%%% Start of article front matter
\begin{frontmatter}

\begin{fmbox}
\dochead{Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Performance of Eventual Consistency and Per-record Timeline Consistency 
in Geo-replicated Systems}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Specify information, if available,       %%
%% in the form:                             %%
%%   <key>={<id1>,<id2>}                    %%
%%   <key>=                                 %%
%% Comment or delete the keys which are     %%
%% not used. Repeat \author command as much %%
%% as required.                             %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\author[
   addressref={aff1},                   % id's of addresses, e.g. {aff1,aff2}
   corref={aff1},                       % id of corresponding address, if any
%   noteref={n1},                        % id's of article notes, if any
   email={mdediana@ime.usp.br}   % email address
]{\inits{MDD}\fnm{Mauricio} \snm{De Diana}}
\author[
   addressref={aff1},
   email={gerosa@ime.usp.br}
]{\inits{MAG}\fnm{Marco Aurélio} \snm{Gerosa}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%% Repeat \address commands as much as      %%
%% required.                                %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address[id=aff1]{%                           % unique id
  \orgname{Computer Science Department, University of São Paulo (USP)}, % university, etc
  \street{R. do Matão, 1010 - Vila Universitária, São Paulo - SP},                     %
  %\postcode{05508-00}                                % post or zip code
  \city{São Paulo},                              % city
  \cny{Brazil}                                    % country
}
%\address[id=aff2]{%
%  \orgname{Marine Ecology Department, Institute of Marine Sciences Kiel},
%  \street{D\"{u}sternbrooker Weg 20},
%  \postcode{24105}
%  \city{Kiel},
%  \cny{Germany}
%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter short notes here                   %%
%%                                          %%
%% Short notes will be after addresses      %%
%% on first page.                           %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{artnotes}
%\note{Sample of title note}     % note to the article
%\note[id=n1]{Equal contributor} % note, connected to author
\end{artnotes}

\end{fmbox}% comment this for two column layout

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% Please refer to the Instructions for     %%
%% authors on http://www.biomedcentral.com  %%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstractbox}

\begin{abstract} % abstract
Large-scale web systems use data replication among data centers to achieve high
levels of performance and availability, trading off these attributes against
consistency.  Consistency models define the consistency guarantees that a system
provides and its trade-offs.  Eventual consistency is a more relaxed consistency
model, widely deployed in large-scale systems. By its turn, the less popular
per-record timeline consistency strikes a better balance when requirements over
consistency are more restrictive. However, to be able to make a decision,
developers need to understand its performance penalties and the situations when
they apply. 

Here we show that under certain workloads and network conditions, a storage
system exhibits similar performance for both consistency models. The
experimental results confirm that a system under per-object timeline consistency
and exhibiting high data locality and read/write ratios suffer a low performance
hit compared to the same system under eventual consistency. This comparative
helps developers and system administrators on cost estimates and capacity
planning of large-scale systems.
%\parttitle{First part title} %if any
%Text for this section.

%\parttitle{Second part title} %if any
%Text for this section.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The keywords begin here                  %%
%%                                          %%
%% Put each keyword in separate \kwd{}.     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{keyword}
\kwd{distributed systems}
\kwd{consistency models}
\kwd{large scale web systems}
\kwd{performance analysis}
\end{keyword}

% MSC classifications codes, if any
%\begin{keyword}[class=AMS]
%\kwd[Primary ]{}
%\kwd{}
%\kwd[; secondary ]{}
%\end{keyword}

\end{abstractbox}
%
%\end{fmbox}% uncomment this for twcolumn layout

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% Please refer to the instructions for     %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and include the section headings         %%
%% accordingly for your article type.       %%
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% start of article main body
% <put your article body there>

\section{Introduction}

To continuously serve users world-wide with low response times, large-scale web
systems replicate data across servers spread over multiple data centers located
in different geographical locations. Such structure poses challenges to
maintaining the consistency among the replicas, mainly due to network latencies
and node / network failures.

Developers and administrators of such systems need to seek a balance between
consistency, performance and availability. Several consistency models have been
described in the literature, each of them defining a different set of
conditions, guarantees and trade-offs. A common decision in large-scale systems
is the use of more relaxed consistency models to achieve low latency and high
availability. However, inconsistencies are more likely to happen with more
relaxed consistency models.

Eventual consistency is a more relaxed consistency model which has become
popular after the publication of the Dynamo paper \cite{DeCandia2007}. Eventual
consistency guarantees that, once updates cease, all replicas will converge to
the same value at some moment in the future. As long as updates are occurring,
replicas may be inconsistent and clients may read stale or divergent values
depending on which replica processes a given request. From that comes the need
for the application to implement conflict resolution mechanisms and compensation
actions to handle the results of actions taken based on inconsistent state. The
added complexity negatively affects code maintainability and system operations.

Some web applications strictly require high availability levels. For example,
Amazon needs its users to be able to add items to their shopping cart even if it
leads to some error that must be handled afterwards \cite{DeCandia2007}.

However, eventual consistency is not appropriate for every case, some systems
need stronger consistency models. An example is a bidding application that
cannot allow conflicts on bidding history. If eventual consistency is used and a
network partition happens, users bidding in the different sides of the partition
will lead up to divergent bidding histories. Furthermore, developers of
applications with less strict availability requirements can benefit from simpler
assumptions when programming.

Per-object timeline consistency stays inr the middle ground between
linearizability \cite{Herlihy1990} and eventual consistency. It was first
implemented in the PNUTS database system, developed by Yahoo!
\cite{Cooper2008}. Under this consistency model, each object has a master
replica, which is the only replica allowed to apply updates. By serializing
updates in the master replica, conflicts among replicas cannot happen since
every replica receive the updates in the same order. Moreover, the most recent
value is known at any time, it is the value stored in the master replica.
However, since updates are asynchronous, stale reads due to latency can happen.
Objects are versioned and read requests carry the required version, which can
be a specific version, the most recent (served exclusively by the master) or
any version. The main drawback of per-record timeline consistency is that
updates and most recent reads become unavailable in case of a failure
preventing the communication between a client and the master replica.

Per-object timeline consistency may be a better fit than eventual consistency
for web applications where users tolerate some level of unavailability. Also,
besides availability, performance must also be considered. The main performance
hit in per-record timeline consistency is due to the cost of updates and
consistent reads when the request must traverse a wide-area network (WAN) to
reach the master replica in another data center. However, specific conditions
may alleviate this issue, such as high access locality rates and high
read/write ratios. In fact, PNUTS authors observed up to 85\% locality rate and
94\% of read/write ratio in a study of Yahoo's applications \cite{Cooper2008,
Kadambi2011}. Based on that, they implemented heuristics that improve
per-record timeline consistency performance.

This study compared the performance of a geo-replicated storage system under
eventual consistency and per-record timeline consistency under different
workloads and network conditions. The results make a useful resource for
developers and system administrators estimating system development costs and
doing capacity planning.

%% ------------------------------------------------------------------------- %%
\section{Eventual Consistency and Per-record Timeline Consistency}

Eventual consistency guarantees that once updates cease, all replicas will
converge to the same value. While updates are happening, replicas might be
inconsistent and clients may access outdated or divergent data -- consequently,
the system must implement algorithms for conflict detection and resolution. A
system may use quorums to reduce the chances of conflicts, the drawback is
decreased availability when a specific quorum can not be reached due to node or
network failures \cite{Vogels2009}.  Quorums are commonly defined by the
\textit{N}, \textit{R} and \textit{W} parameters: \textit{N} is the replication
factor and represents the number of replicas of a given object in the system.
\textit{R} and \textit{W} are respectively the amount of replicas that need to
agree on the same value for a read and for a write to be successful.  $N < R +
W$ eliminates the possibility of clients reading inconsistent data, since there
is an intersection between the subsets of replicas for reading and writing.

Reasoning about a web application is simpler under a more strict consistency
model. For example, an auction site cannot tolerate conflicts in the bidding
history of a product. In a system under eventual consistency, in case of a
failure that splits the network in two or more partitions, users acting in each
partition will have their own view of the bidding history, what is equivalent
to two or more simultaneous auctions for the same item.

Per-object timeline consistency trades availability for consistency in some
situations \cite{Cooper2008}. For each stored object, it allows updates only to
one of its replicas, the master replica. Due to asynchronous replication,
replicas may have different values due to network latency or network failure,
however, at any given moment, the most up-to-date replica is known. In every
read, clients choose whether to accept only the most recent, any value or a
specific version of the object. Due to the master replica establishing an
update ordering to the other replicas, divergences do not happen and conflict
detection and resolution mechanisms are not needed. The main drawback of
per-record timeline consistency is that the use of a master replica leads to
unavailability of writes and most recent reads in the event of a node or
network failure that renders it unreachable.

The highest impact factor in the performance of per-record timeline consistency
is the fact that consistent operations that are not made in the master
replica's data center incur the cost of communication over a WAN.  However, the
authors of PNUTS point that some applications on Yahoo! exhibit access locality
up to 85 \% and write / read ratio as low as 6\% \cite{Kadambi2011,
Cooper2008}.  A social network application fits this pattern, most users access
the application from the same geographic location and a post or picture is
written once (or edited few times at most) but read several times. Thus, in an
application in which the amount of reads is much greater than the amount of
writes, network communication costs are low, especially if reads do not
necessarily need the latest value.  The authors of PNUTS implemented a simple
heuristic by which the master replica migrates to the data center that
processed the three latest writes of the object. Back to the social network
example, this would be the case of a user moving to another country, for
example, and starting accessing the system from the new place.

%% ------------------------------------------------------------------------- %%
\section{Experiment Planning}

We performed an experiment to compare the performance of eventual consistency
and per-object timeline consistency under different situations. Planning and
execution used \cite{Jain1991} as the main methodological reference.

The three techniques available for system performance analysis are simulation,
analytical modeling and measurement \cite{Jain1991}. We picked measurement, as
33 parameters were initially considered for this study (see following section),
simulators and models were discarded because the needed simplifications to
apply them would result in loss of accuracy.

To be able to accurately compare the consistency models without interference of
software architecture and technology stack factors, the experiment should make
use of a single system with both consistency models. As no such system has been
found, we implemented per-record timeline consistency in Riak, a free software
system which already implements eventual consistency \cite{Riak2013}. Besides
the new consistency model, we also implemented a partitioning algorithm that
ensures that there exist at least one replica of each object in each data
center \cite{DeDiana2013a, DeDiana2013b}.

For running the experiments and gathering results, we used the Riak benchmark
Basho Bench \cite{BashoBench2013}. We adapted it to be able to run more than a
single instance simultaneously, with one instance for each data center.

To achieve experiment reproducibility, the use of a real WAN was avoided.
Instead, the experiments emulated a WAN with the Linux tools tc (traffic
control) / netem (Network Emulation). These tools provide functionality for
emulating network characteristics such as latency and packet loss. Network
settings in Linux were configured according to recommended optimizations for
WAN communication \cite{ESnet2012}, for example, the use of the double of the
Bandwidth-Delay Product (BDP) as transmission and reception buffer size.

The experiments were carried out on Grid'5000, a platform for creation,
implementation and monitoring of parallel and distributed system experiments
\cite{Grid50002013}.

The study used factorial design, which consist of a combination of factors in
each experiment comprising the study \cite{Jain1991}. The more factors and
levels in a study, the more resources are needed to its execution.  Moreover,
usually a few factors explain the most effects on the response. Therefore, a
selection of the most influential factors was performed by the use of
2\textsuperscript{k} experiments, which consist of the selection of only the
minimum and maximum levels for each factor, resulting in a total of
2\textsuperscript{k} experiments, where \textit{k} is the number of factors.

%% ------------------------------------------------------------------------- %%
\section{Fixed Parameters}

After defining the experimental design, 33 parameters were listed, 16 of which
were fixed due to resource constraints. With regards to network parameters, the
values of LAN parameters were the actual values found in the cluster, while WAN
parameters were emulated. The fixed parameters and their respective values
were:

\begin{itemize}

\item \textbf{Cluster:} The experiments used the cluster \textit{sol} in
Grid'5000. The nodes in the cluster have AMD Opteron 2218 2.6 GHz CPU, 4 GB RAM
and 1 Gb/s network cards.

\item \textbf{Storage engine:} By using memory as storage mechanism we avoided
the effects of disk and disk cache and the interaction between disk cache and
the amount of available RAM, so the only I/O effects observed in the
experiments were due to the network.

\item \textbf{Data center capacity:} Data centers had the same capacity - the
same number of nodes per data center and nodes with the same hardware
configuration.

\item \textbf{Key partitioning algorithm:} Consistent hashing, which is the
default algorithm in Riak.

\item \textbf{Replication factor ($ N $):} 3, which is the value that results
in a reasonable balance between performance, availability and durability in
real applications \cite{DeCandia2007}.

\item \textbf{Migration threshold (for per-record timeline consistency):} 3,
which is PNUTS default value \cite{Cooper2008}.

\item \textbf{Interface access:} HTTP, due to its simplicity.

\item \textbf{Log level:} WARN, since exploratory experiments showed loss of
performance when the logging level was INFO.

\item \textbf{Hardware configuration of intermediary network devices:} The
single network device was a FastIron Super X switch, tests have shown there were
no bottlenecks in the switch even in experiments with high consumption of bandwidth.

\item \textbf{Network topology:} Star, the only network topology available in
the cluster.

\item \textbf{LAN bandwidth:} 1 Gb/s, which was the bandwidth provided by the
network cards contained in the nodes.

\item \textbf{LAN latency:} $167\mu$s latency cluster measured with 60 samples
of pings separated by 5 s.

\item \textbf{LAN jitter:} $90\mu$s, jitter measured by the same means as
latency.

\item \textbf{WAN bandwidth:} 100 Mb/s, based on informal study citing this was
the commonly observed bandwidth between AWS availability zones
\cite{Pujol2012}.

\item \textbf{Number of WAN links:} 1, which means two simulated data centers.

\item \textbf{Request arrival rate:} 15 operations/s for each thread of each
benchmark instance.

\end{itemize}

There were 17 remaining candidate factors. Three of them were combined in a
single factor, the mode.

%% ------------------------------------------------------------------------- %%
\section{Mode}

Three factors interacted in a particular way, their different combinations
result in different ratios of local/remote requests. The factors are:
consistency model, replication configuration (for eventual consistency) and
required version for reads (for per-record timeline consistency). Thus, these
factors were treated as a single factor, \textit{mode}. The modes were:

\begin{itemize}

\item \textit{ev1}: Eventual consistency with $W$ = 1 and $R$ = 1

\item \textit{ev2}: Eventual consistency with $W$ = 2 and $R$ = 1

\item \textit{any}: Per-object timeline consistency with reads of any version

\item \textit{lat}: Per-object timeline consistency with reads of latest version

\end{itemize}

Given a replication factor of 3 and that each data center had one or two
replicas of each object (never none), two situations were possible from the
client standpoint with respect to the location of replicas: one local and two
remote or vice versa. Thus, the proportion of reads and writes for each mode
were:

\begin{itemize}

\item \textit{ev1}: all reads and writes could be performed in the local data
center.

\item \textit{ev2}: all reads and 50\% of writes could be performed in the
local data center while 50\% of write operations needed to traverse the WAN to
access the second replica.

\item \textit{any}: all reads could be performed in the local data center and
the proportion of writes in the local or remote data center depended on data
access locality.

\item \textit{lat}: both reads and writes depended on data access locality. 

\end{itemize}

It is worth noting that these modes involve other trade-offs than performance
and consistency. For example, durability is higher for \textit{ev2} than for
the other modes in which write confirmation of a single replica is sufficient.

After defining the mode factor, 14 candidate factors remained, too many for the
final study. We performed 2\textsuperscript{k} experiments to reduce this
amount in an informed way.

%% ------------------------------------------------------------------------- %%
\section{Factor Selection}

An approach for the selection of factors would group all candidate factors in a
single 2\textsuperscript{k} experimental study. This approach would not work
because even considering only two levels by factor, it would lead to
2\textsuperscript{14} experiments, still prohibitive.

We splitted the experiments into smaller groups of related factors, assuming
that unrelated factors would have little to no interaction between them, and
ran experiments for each group separately. With that, comparison between
factors of different groups and their interactions was lost. However, since
most factors have shown little influence inside their groups, as shown in the
following subsections, this approach did not present a threat to validity.

Most factors were prone to interactions with network factors. The WAN latency
in particular had been very influential in exploratory studies, fact later
confirmed by the study of network factors. Given that, we used WAN latency as a
representative of network factors when necessary.

There were cases where the results of all experiments of a study were similar,
regardless of the factor levels. To handle such cases we used the coefficients
of variation (CVs) of the responses as an estimate of the influence of that set
of factors and interactions as a whole. Thus, a low CV indicated that none of
the factors were influential.

For per-record timeline consistency, we implemented a warmup phase after data
load and before the experiment. At the end of the load stage each object in the
database had received a single access from each data center, thus no master
replicas had migrated yet. So, during the warmup phase, objects were accessed
according to the locality of the experiment to force master migrations before
the start of the experiment.

We conducted four intermediate studies, they are described in the following
subsections. Whenever mode and locality had to be fixed, they were fixed
respectively at \textit{lat} and 50\%, values that result in a balanced amount
of reads and writes, both local and remote. When necessary, latency was fixed
at 100~ms. In the results, the 10 and 90 percentiles represent respectively
local and remote requests.

%% ------------------------------------------------------------------------- %%
\subsection{System size and benchmark size factors}

The number of nodes and benchmark instances not only influenced the
responses, it also influenced operational issues related to node reservation --
by Grid'5000 rules, the greater the number of reserved nodes, the smaller the
reservation time. Therefore, a study was done to determine the influence of
these factors. We used the following levels, the value in parentheses
being the identifier of the factor in the tables with results below:

\begin{itemize}

\item Number of system nodes (N): 8 and 16

\item Number of benchmark instances (B): 2 and 4

\item Number of threads in each benchmark instance (T): 32 and 64

\end{itemize}

The result of the study is shown in Table
\ref{tab:estudo_para_fatores_de_tamanho_do_sistema}. The system size had greater
influence on the results and the number of benchmark instances and threads were
not negligible, specially considering the interactions between them.
Nevertheless, these factors were disregarded due to the excessive number of
factors.

\begin{table}[h!]
\caption{Study for system size factors.}
\begin{tabular}{ccccccccc} \hline

Operation & Percentile & N & B & T & NB & NT & BT & NBT\\\hline

read & 10 & 30 & 18 & 22 & 10 & 8 & 7 & 4 \\

read & 90 & 65 & 13 & 15 & 3 & 4 & 0 & 0 \\

write & 10 & 96 & 2 & 1 & 0 & 0 & 0 & 0 \\

write & 90 & 65 & 15 & 13 & 3 & 3 & 0 & 0 \\\hline

\end{tabular}
\label{tab:estudo_para_fatores_de_tamanho_do_sistema} \end{table}

Given the results, the fixed values were:

\begin{itemize}

\item Number of system nodes: 16

\item Number of benchmark instances: 4

\item Number of threads in each benchmark instance: 32

\end{itemize}

These values were selected because they resulted in the ``lightest''
configuration, avoiding network bottlenecks and system overload. Although
desirable, a greater number of nodes would imply lack of hardware homogeneity
and operational difficulties due to the Grid'5000 rules.

%% ------------------------------------------------------------------------- %%
\subsection{Database factors}

The database size would affect memory usage and bandwidth comsumption in the
nodes. The levels used in the study were:

\begin{itemize}

\item Number of stored objects (O): 64,000 and 256,000

\item Object sizes (S): 100 and 10,000 bytes

\end{itemize}

The result of the study is shown in Table
\ref{tab:estudo_para_fatores_de_banco_de_dados}. The number of objects did not
affect system performance. Object size did not affect performance of remote
requests, however, they correspond to 100\% of influence regarding local
requests. Nevertheless, the CV of local requests indicated that their influence
was not as great - 19\% for reads and 16\% for writes.

\begin{table}[h!]
\caption{Study for database factors, L is for latency.}
\begin{tabular}{ccccccccc} \hline

Operation & Percentile & O & S & L & OS & OL & SL & OSL\\\hline

read & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\

read & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0 \\

write & 10 & 0 & 100 & 0 & 0 & 0 & 0 & 0 \\

write & 90 & 0 & 0 & 100 & 0 & 0 & 0 & 0 \\\hline

\end{tabular}
\label{tab:estudo_para_fatores_de_banco_de_dados} \end{table}

Given the results, the fixed values were:

\begin{itemize}

\item Number of stored objects: 128,000

\item Object sizes: 500

\end{itemize}

The number of stored objects influenced the warmup time, thus the lower the
number, the faster the execution of experiments. Conversely, a too small number
would result in an excessive number of conflicts for eventual consistency. For
the size of stored objects, the value was chosen based on a study of caching
systems on Facebook, which reports that 90\% of the objects are smaller than
500 bytes \cite{Atikoglu2012}.

%% ------------------------------------------------------------------------- %%
\subsection{Network factors}

Given the purpose of this work, the study for network factors was one of the
most important for the factor selection. The levels were as follows:

\begin{itemize}

\item WAN latency (L): 100 and 300 ms

\item WAN jitter (J): 1 and 60\%

\item WAN packet loss rate (P): 0.01 and 0.3\%

\item WAN packet duplication rate (D): 0.05 and 5\%

\item WAN packet reordering rate (R): 0.05 and 5\%

\item TCP variant (V): CUBIC and H-TCP

\end{itemize}

Latency levels were based on a study reporting latencies between regions of the
Amazon Web Services \cite{Sovran2011}, in which the lowest latency between data
centers in each U.S. coast was 82 ms and the highest was 277 ms between Ireland
and Singapore.

Project PingER served as the basis for other factors \cite{PingER2013}. In
January 2013, it shows an average latency of 238.062 ms with standard deviation
142.996 ms, resulting in a jitter of 60\%. The previous 11 months show similar
figures. The median packet loss rate was 0.178\%. The average packet
duplication rate in January 2013 was 0.006\%. The values used in the experiment
for duplication and reordering were higher than those observed by PingER, yet
they did not influence the response.

Both H-TCP and CUBIC were designed with a focus on high bandwidth, high latency
networks (high BDP), and appear in references about TCP tuning for WANs
\cite{ESnet2012}.

In the emulated network, latency defines the minimum level and jitter defines
the maximum value that latency can reach. For example, when latency is
configured as 100~ms and variation as 60\%, the emulator generates latency
values between 100~ms and 160~ms. The generated values followed the normal
distribution within the specified range of latency.

The result of the study is presented in Table
\ref{tab:estudo_para_fatores_de_rede}, columns of interactions between factors
with all cells less than 1\% were suppressed for the sake of space. The
responses of local requests showed CVs of 1\%, so their rows were also
suppressed -- which indicates that WAN does not affect local requests.

\begin{table}[h!] 
\caption{Network factors study.} \label{tab:estudo_para_fatores_de_rede}
\begin{tabular}{ccccccccc} \hline

Operation & Percentile & L & J & P & D & R & V & LJ\\\hline

read & 90 & 72 & 21 & 1 & 0 & 0 & 0 & 6\\

write & 90 & 69 & 23 & 1 & 0 & 0 & 0 & 6\\\hline

\end{tabular}

\end{table}

Latency, jitter and the first order interaction between them make up for close to 100\% of the response. Therefore, the selected levels for
these factors were:

\begin{itemize}

\item WAN latency (ms): 0, 100, 200 and 300

\item WAN jitter (\%): 0 and 60

\end{itemize}

Latency and jitter at zero are equivalent to having the entire system operating
over a LAN. The results obtained in these cases were used as aid in the
interpretation of other results, but were not considered in the final study.

The fixed values of the disregarded factors were:

\begin{itemize}

\item WAN packet loss rate: 0\%

\item WAN packet duplication rate: 0\%

\item WAN packet reordering rate: 0\%

\item TCP variant (T): CUBIC

\end{itemize}

%% ------------------------------------------------------------------------- %%
\subsection{Workload factors}

Along with network factors, this was one of the most important studies. The
levels used were as follows:

\begin{itemize}

\item Read / write ratio (R): 2:1 and 10:1

\item Object popularity (P): uniform (the average of the request arrival rate
for each object is the same) and skewed (the arrival rate follows a Pareto
distribution)

\item Locality (X): 50\% (no locality) and 90\% (90\% of accesses to a given
object coming from one data center and 10\% from the other)

\end{itemize}

As the modes behave differently depending on locality, we performed one set of
experiments for each mode.

The read/write ratio and locality did not use percentiles, they used the
average of response times for reads and writes instead. The read/write ratio
relates to the composition between reads and writes, while locality alters
the composition between local and remote requests, so these factors did not
make sense in percentiles separated by request type. For example, 50\% locality
means that the 70th percentile is remote requests, while with 90\% locality the
same percentile represents local requests. If the analysis was performed based
off percentiles, this location information would be lost and locality would
never have any influence.

The result of the study is shown in Table
\ref{tab:estudo_para_fatores_de_carga_de_trabalho}, in which columns with all
values smaller than 5\% were removed for the sake of space. The results for
local requests showed CVs around 2\% for all modes, indicating that none of the
factors influenced local requests.

\begin{table}[h!]
\caption{Study for workload factors, L is latency.}
\begin{tabular}{cccccccccc} \hline

Mode & R & X & P & L & RX & RL & XL & PL & XPL\\\hline

\textit{ev1} & 19 & 12 & 2 & 31 & 0 & 2 & 6 & 6 & 8\\

\textit{ev2} & 50 & 0 & 0 & 39 & 0 & 11 & 0 & 0 & 0\\

\textit{any} & 25 & 30 & 0 & 19 & 9 & 6 & 8 & 0 & 0\\

\textit{lat} & 0 & 53 & 0 & 34 & 0 & 0 & 13 & 0 & 0\\\hline

\end{tabular} 
\label{tab:estudo_para_fatores_de_carga_de_trabalho}
\end{table}

As expected, locality and latency influenced responses in general. The impact
of popularity of objects is virtually nil. Although some modes were apparently
impacted by read/write ratio, this impact was a consequence of the relationship
between local and remote requests. For \textit{ev1}, both reads and writes are
local and the read/write ratio and their interactions with other factors have
little impact in this mode. For \textit{lat}, reads and writes are local or
remote depending on locality and read/write ratio does not impact this mode.
For \textit{ev2}, all reads are local and half of writes are remote, therefore
when the read/write ratio changes, the ratio between local and remote requests
changes proportionally -- as expected, this mode is impacted by the read/write
ratio. The same observation holds for \textit{any}, for which all reads are
local and writes depend on locality, so it is impacted by the read/write ratio.
The read/write ratio would likely influence the response if the storage
mechanism was disk instead of memory, since writes would be affected by the
write time to disk, while reads could be faster due to disk caching.

Therefore, only locality was selected as a factor:

\begin{itemize}

\item Locality (\%): 50 and 90

\end{itemize}

The fixed values of the disregarded factors were:

\begin{itemize}

\item Read/write ratio: 2:1

\item Object popularity: uniform

\end{itemize}

%% ------------------------------------------------------------------------- %%
\section{Final Study}

The final study consisted of a total of 64 experiments with the factors
selected by the 2\textsuperscript{k} studies.
Table~\ref{tab:fatores_e_niveis_do_estudo_final} shows the final factors and
respective levels. Two replications of the study were used to estimate the
variability of the experiments, the measured average CVs were 1\% for reads and
0.8\% for writes.

\begin{table}[h!]
\caption{Factors and levels in the final study.}
\begin{tabular}{lcc} \hline

Factor & Levels & Number of levels\\\hline

Mode & \textit{ev1}, \textit{ev2}, \textit{any} e \textit{lat} & 4\\

WAN latency (ms) & 0, 100, 200 and 300 & 4\\

WAN jitter (\%) & 0 and 60 & 2\\

Locality & 50\% and 90\% & 2\\\hline

\end{tabular}

\label{tab:fatores_e_niveis_do_estudo_final}

\end{table}

The system showed similar behavior for 100~ms, 200~ms and 300~ms latency
levels, so we used only one of them on the presentation of the final results.
The boxplot for the 200~ms latency level is shown in Figure
\ref{fig:boxplot_dos_tempos_de_resposta}. A box not showing in the figure
indicates that all requests delimited by the boxplot whiskers were local. The
same analysis was done with maximum load instead of 15 operations/s per thread.
As Figure~\ref{fig:boxplot_dos_tempos_de_resposta_para_carga_maxima} shows, all
modes showed an increase in response times, but the general behavior remained
the same.

\begin{figure}[h!]
\caption{Boxplot of response times for 15 operations/s per thread.}
\includegraphics[width=1.0\textwidth]{boxplot200.png}
\label{fig:boxplot_dos_tempos_de_resposta}
\end{figure}

\begin{figure}[h!]
\caption{Boxplot of response times for maximum load per thread.}
\includegraphics[width=1.0\textwidth]{boxplot200_max.png}
\label{fig:boxplot_dos_tempos_de_resposta_para_carga_maxima}
\end{figure}

%% ------------------------------------------------------------------------- %%
\section{Discussion}

The goal of this study was to compare the performance of a system under
eventual consistency and per-object timeline consistency to verify if and under
which conditions the latter was an alternative to the first for geo-replicated
web applications. The experimental results match the expected analytical
results, where per-object timeline consistency shows the same level of
performance as eventual consistency when data locality and read/write ratio are
high.

If data locality is low (50\%), the performance of per-object timeline
consistency is only comparable to eventual consistency for reads of any
version, performance is hit for ``most recent'' reads and writes.
Per-object timeline consistency becomes an interesting option when data
locality is high (90\%), since most of reads and writes are local. Given that
reads of any version perform well under low data locality, per-object timeline
consistency can also be an option for applications where the read/write ratio
is high and slow writes are tolerable.

Even in cases where data locality and read/write ratio are high, per-object
timeline consistency may be discarded as an option due to performance
variability. For applications where response time requirements are on the 99.9
percentile, such as Amazon \cite{DeCandia2007}, per-record timeline consistency
is not appropriate.

The main advantages of per-record timeline consistency over eventual
consistency are the guarantee that conflicting updates do not occur and that
the location of the most recent value is known at all times. An interesting
scenario for its use is the case where the application tolerates staleness for
most of its reads, but needs the most recent value for a few. Per-object
timeline consistency main drawbacks are that writes and ``most recent'' reads
become unavailable if the master replica is unavailable and its relatively high
response time variability.

Reasoning about an application under per-object timeline consistency is easier
than under eventual consistency. Implementing per-object timeline consistency
in a storage system is less complex than eventual consistency since no conflict
detection and resolution mechanisms are necessary. This impact the cost of
development and maintenance of storage systems and applications. The only
system implementing per-object timeline consistency is PNUTS, which is not
distributed outside Yahoo!. This opens an opportunity for companies or the open
source community to provide this consistency model in new or existing systems.

A final contribution of this work, especially to the research community, is its
detailed experimental design. By conducting formal factor and level selections,
we have a better understanding of the reliability and the limitations of the
findings.

Consistency in distributed systems is an important topic given the global scale
of web operations. Studies and benchmarks comparing performance and
availability of other consistency models under different conditions is
important to advance research and support informed decision by practitioners.

%% ------------------------------------------------------------------------- %%
\section{Threats to Validity}

Some parameters were fixed and influential parameters were disregarded. Thus,
studies that use other values for the parameters or take different factors into
consideration may yield different results. This is particularly true for the
number of system nodes, which showed as highly influential in the preliminary
studies. In addition, levels at different ranges may yield different results
\cite{Jain1991}.

The experiments did not take node failures into account. Experiments with the
system operating in a failure mode (from the failure of a single node to a
whole data center) will likely yield to different results. Such situations were
not part of the experiments due to resource limitations.

%% ------------------------------------------------------------------------- %%
\section{Related Work}

A common approach in the distributed systems literature is the proposal of a
new concept and the implementation of that concept into a system accompanied by
a performance analysis. The Dynamo \cite{DeCandia2007} and the PNUTS papers
\cite{Cooper2008} show performance analyses. A second paper about PNUTS
analyzes bandwidth consumption under different replication policies for
communication over WANs \cite{Kadambi2011}.

Several papers present performance analyses of storage systems using
replication over WANs. In most cases, the goals of the systems are to prove
ideas other than the efficiency of their consistency model. COPS uses causal+
consistency that is similar to causal consistency with extended guarantees and
implements transactions \cite{Lloyd2011}. Scatter proposes an scalable
architecture for a strong consistent system \cite{Glendenning2011}. Windows
Azure provides a cloud storage system with strong consistency
\cite{Calder2011}. Megastore uses Paxos to implement strong consistency
\cite{Baker2011}. None of these works present comparisons with other systems or
other consistency models. As they do not use a common benchmark or the same
environment, it is difficult to compare them.

The different consistency options in Cassandra and the resulting availability
and performance were analyzed in \cite{Beyer2011}, the conclusion is that
more strict consistency models perform worse. Performance and availability of
master-slave replication and chain replication are compared in
\cite{vanRenesse2004}, each of them under strong consistency and eventual
consistency. None of these studies consider operation over WANs or different
workloads.

A comparison between Cassandra, HBase, PNUTS and sharded MySQL under different
workloads can be found in \cite{Cooper2010}. The focus of this work is the
comparison of the systems performace, but not much can be said about their
consistency models since they have different architectures, implementations and
configuration options. Moreover, it only considers the systems operating in a
LAN, not a WAN.

%% ------------------------------------------------------------------------- %%
\section{Conclusions}

Developers and administrators trade-off between consistency, performance and
availability to meet the requirements of large-scale web application. This
study compared the performance of a storage system operating over a WAN under
two different consistency models. The results show that per-object timeline
consistency is competitive with eventual consistency when write locality is
high and when stale reads are an option.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Backmatter begins here                   %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{backmatter}

%\section*{Competing interests}
%  The authors declare that they have no competing interests.

%\section{Author's contributions}
%    Text for this section \ldots

\section*{Acknowledgements}
Experiments presented in this paper were carried out using the Grid'5000
experimental testbed, being developed under the INRIA ALADDIN development
action with support from CNRS, RENATER and several Universities as well as
other funding bodies.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%
%%  Bmc_mathpys.bst  will be used to                       %%
%%  create a .BBL file for submission.                     %%
%%  After submission of the .TEX file,                     %%
%%  you will be prompted to submit your .BBL file.         %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %%
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %%
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% if your bibliography is in bibtex format, use those commands:
\bibliographystyle{bmc-mathphys} % Style BST file (bmc-mathphys, vancouver, spbasic).
\bibliography{bmc_article}      % Bibliography file (usually '*.bib' )
% for author-year bibliography (bmc-mathphys or spbasic)
% a) write to bib file (bmc-mathphys only)
% @settings{label, options="nameyear"}
% b) uncomment next line
%\nocite{label}

% or include bibliography directly:
% \begin{thebibliography}
% \bibitem{b1}
% \end{thebibliography}

\end{backmatter}
\end{document}
